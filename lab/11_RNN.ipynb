{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P95c6hK3hAQq"
      },
      "source": [
        "# Rekurencyjne Sieci Neuronowe (RNN)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "laVdd5g5hAQu"
      },
      "source": [
        "### Importy i Utilsy  (odpalić i schować )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "I0D3yk7lhAQu"
      },
      "outputs": [],
      "source": [
        "# imports \n",
        "import torch\n",
        "import os\n",
        "import unicodedata\n",
        "import string\n",
        "import numpy as np\n",
        "from typing import Tuple, Optional, List\n",
        "\n",
        "from torch.nn.functional import cross_entropy\n",
        "\n",
        "import matplotlib.pyplot as plt \n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "all_letters = string.ascii_letters\n",
        "n_letters = len(all_letters)\n",
        "\n",
        "\n",
        "class ListDataset(Dataset):\n",
        "    \n",
        "    def __init__(self, data, targets):\n",
        "        \n",
        "        self.data = data\n",
        "        self.targets = targets\n",
        "        \n",
        "    def __getitem__(self, ind):\n",
        "        \n",
        "        return self.data[ind], self.targets[ind]\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.targets)\n",
        "\n",
        "    \n",
        "def unicode_to__ascii(s: str) -> str:\n",
        "    return ''.join(c for c in unicodedata.normalize('NFD', s) if unicodedata.category(c) != 'Mn'\n",
        "                                                                 and c in all_letters)\n",
        "                   \n",
        "\n",
        "def read_lines(filename: str) -> List[str]:\n",
        "    lines = open(filename, encoding='utf-8').read().strip().split('\\n')\n",
        "    return [unicode_to__ascii(line) for line in lines]\n",
        "\n",
        "\n",
        "def letter_to_index(letter: str) -> int:\n",
        "    return all_letters.find(letter)\n",
        "\n",
        "\n",
        "def line_to_tensor(line: str) -> torch.Tensor:\n",
        "    tensor = torch.zeros(len(line), n_letters)\n",
        "    for i, letter in enumerate(line):\n",
        "        tensor[i][letter_to_index(letter)] = 1\n",
        "    return tensor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RcSQvaMPhAQv"
      },
      "source": [
        "## Dane sekwencyjne\n",
        "\n",
        "Modele, którymi zajmowaliśmy się wcześniej zakładały konkretny kształt danych. Dla przykładu klasyczna sieć neuronowa fully-connected dla MNISTa zakładała, że na wejściu dostanie wektory rozmiaru 784 - dla wektorów o innej wymiarowości i innych obiektów model zwyczajnie nie będzie działać.\n",
        "\n",
        "Takie założenie bywa szczególnie niewygodne przy pracy z niektórymi typami danych, takimi jak:\n",
        "* językiem naturalny (słowa czy zdania mają zadanej z góry liczby znaków)\n",
        "* szeregi czasowe (dane giełdowe ciągną się właściwie w nieskończoność) \n",
        "* dźwięk (nagrania mogą być krótsze lub dłuższe).\n",
        "\n",
        "Do rozwiązania tego problemu służą rekuencyjne sieci neuronowe (*recurrent neural networks, RNNs*), które zapamiętują swój stan z poprzedniej iteracji."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mH3chO87hAQv"
      },
      "source": [
        "### Ładowanie danych\n",
        "Poniższe dwie komórki ściągają dataset nazwisk z 18 różnych narodowości. Każda litera w danym nazwisku jest zamieniana na jej indeks z alfabetu w postaci kodowania \"one-hot\". Inaczej mówiąc, każde nazwisko jest binarną macierzą rozmiaru `n_letters` $\\times$ `len(name)`. \n",
        "\n",
        "Dodatkowo, ponieważ ten dataset jest mocno niezbalansowany, użyjemy specjalnego samplera do losowania przykładów treningowych, tak aby do uczenia sieć widziała tyle samo przykładów z każdej klasy.\n",
        "\n",
        "Ponieważ nazwiska mogą mieć różne długości będziemy rozważać `batch_size = 1` w tym notebooku (choć implementacje modeli powinny działać dla dowolnych wartości `batch_size`!)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "maOHB6NZiRgr"
      },
      "outputs": [],
      "source": [
        "!wget https://download.pytorch.org/tutorial/data.zip\n",
        "!unzip data.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "DRGjkPZ2hAQv"
      },
      "outputs": [],
      "source": [
        "# NOTE: you can change the seed or remove it completely if you like\n",
        "torch.manual_seed(1337)\n",
        "\n",
        "data_dir = 'data/names'\n",
        "\n",
        "# Build the category_lines dictionary, a list of names per language\n",
        "category_lines = {}\n",
        "all_categories = []\n",
        "\n",
        "data = []\n",
        "targets = [] \n",
        "label_to_idx = {}\n",
        "\n",
        "# read each natonality file and process data \n",
        "for label, file_name in enumerate(os.listdir(data_dir)):\n",
        "    \n",
        "    label_to_idx[label] = file_name.split('.')[0].lower()\n",
        "    \n",
        "    names = read_lines(os.path.join(data_dir, file_name))\n",
        "    data += [line_to_tensor(name) for name in names]\n",
        "    targets += len(names) * [label]\n",
        "\n",
        "# split into train and test indices\n",
        "test_frac = 0.1\n",
        "n_test = int(test_frac * len(targets))\n",
        "test_ind = np.random.choice(len(targets), size=n_test, replace=False)\n",
        "train_ind = np.setdiff1d(np.arange(len(targets)), test_ind)\n",
        "\n",
        "targets = torch.tensor(targets)\n",
        "train_targets = targets[train_ind]\n",
        "\n",
        "# calculate weights for BalancedSampler\n",
        "uni, counts = np.unique(train_targets, return_counts=True)\n",
        "weight_per_class = len(targets) / counts\n",
        "weight = [weight_per_class[c] for c in train_targets]\n",
        "# preapre the sampler\n",
        "sampler = torch.utils.data.sampler.WeightedRandomSampler(weights=weight, num_samples=len(weight)) \n",
        "\n",
        "train_dataset = ListDataset(data=[x for i, x in enumerate(data) if i in train_ind], targets=train_targets)\n",
        "train_loader = DataLoader(train_dataset, shuffle=False, batch_size=1, sampler=sampler)\n",
        "\n",
        "test_dataset = ListDataset(data=[x for i, x in enumerate(data) if i in test_ind], targets=targets[test_ind])\n",
        "test_loader = DataLoader(test_dataset, shuffle=False, batch_size=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Yvstu1-sldC6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6093195d-05c0-494b-f4bd-d32089db25fc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x.shape: torch.Size([1, 9, 52])\n",
            "name: OLoughlin\n",
            "y: irish\n"
          ]
        }
      ],
      "source": [
        "# check out the content of the dataset\n",
        "for i, (x, y) in enumerate(train_loader):\n",
        "    break\n",
        "\n",
        "print(\"x.shape:\", x.shape)\n",
        "print(\"name: \", end=\"\")\n",
        "for letter_onehot in x[0]:\n",
        "    print(all_letters[torch.argmax(letter_onehot)], end=\"\")\n",
        "\n",
        "print(\"\\ny:\", label_to_idx[y.item()])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x3VdtPOhhAQw"
      },
      "source": [
        "## Zadanie 1. (2 pkt.)\n",
        "\n",
        "Zaimplementuj \"zwykłą\" sieć rekurencyjną. \n",
        "![rnn](https://colah.github.io/posts/2015-08-Understanding-LSTMs/img/RNN-unrolled.png)\n",
        "\n",
        "* W klasie `RNN` należy zainicjalizować potrzebne wagi oraz zaimplementować główną logikę dla pojedynczej chwili czasowej $x_t$\n",
        "* Wyjście z sieci może mieć dowolny rozmiar, potrzebna jest również warstwa przekształacjąca stan ukryty na wyjście.\n",
        "* W pętli uczenia należy dodać odpowiednie wywołanie sieci. HINT: pamiętać o iterowaniu po wymiarze \"czasowym\".\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 255,
      "metadata": {
        "id": "WNu0vccJhAQw"
      },
      "outputs": [],
      "source": [
        "class RNN(torch.nn.Module):\n",
        "    \n",
        "    def __init__(self, \n",
        "                 input_size: int,\n",
        "                 hidden_size: int, \n",
        "                 output_size: int):\n",
        "        \"\"\"\n",
        "        :param input_size: int\n",
        "            Dimensionality of the input vector\n",
        "        :param hidden_size: int\n",
        "            Dimensionality of the hidden space\n",
        "        :param output_size: int\n",
        "            Desired dimensionality of the output vector\n",
        "        \"\"\"\n",
        "        super(RNN, self).__init__()\n",
        "\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.input_to_hidden = torch.nn.Linear(input_size + self.hidden_size, self.hidden_size)\n",
        "        \n",
        "        self.hidden_to_output = torch.nn.LogSoftmax(dim=1)\n",
        "    \n",
        "    # for the sake of simplicity a single forward will process only a single timestamp \n",
        "    def forward(self, \n",
        "                input: torch.tensor, \n",
        "                hidden: torch.tensor) -> Tuple[torch.tensor, torch.tensor]:\n",
        "        \"\"\"\n",
        "        :param input: torch.tensor \n",
        "            Input tesnor for a single observation at timestep t\n",
        "            shape [batch_size, input_size]\n",
        "        :param hidden: torch.tensor\n",
        "            Representation of the memory of the RNN from previous timestep\n",
        "            shape [batch_size, hidden_size]\n",
        "        \"\"\"\n",
        "        \n",
        "        combined = torch.cat([input, hidden], dim=1) \n",
        "        hidden = self.input_to_hidden(combined)\n",
        "        output =  self.hidden_to_output(hidden)\n",
        "        return output, hidden\n",
        "    \n",
        "    def init_hidden(self, batch_size: int) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Returns initial value for the hidden state\n",
        "        \"\"\"\n",
        "        return torch.zeros(batch_size, self.hidden_size, requires_grad=True).cuda()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LIe3L-8LhAQw"
      },
      "source": [
        "### Pętla uczenia"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 258,
      "metadata": {
        "id": "xXEsqqvxhAQx",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b83809ae-ecaa-49bc-a7bd-1ed5f62f25d2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0 Progress:  0% Loss: 5.458\n",
            "Epoch: 0 Progress:  0% Loss: 5.355\n",
            "Epoch: 0 Progress:  0% Loss: 5.160\n",
            "Epoch: 0 Progress:  0% Loss: 4.309\n",
            "Epoch: 0 Progress:  0% Loss: 4.544\n",
            "Epoch: 0 Progress:  0% Loss: 5.047\n",
            "Epoch: 0 Progress:  0% Loss: 4.416\n",
            "Epoch: 0 Progress:  0% Loss: 4.087\n",
            "Epoch: 0 Progress:  0% Loss: 4.862\n",
            "Epoch: 0 Progress:  0% Loss: 4.058\n",
            "Epoch: 0 Progress:  0% Loss: 3.725\n",
            "Epoch: 0 Progress:  0% Loss: 3.575\n",
            "Epoch: 0 Progress:  0% Loss: 3.560\n",
            "Epoch: 0 Progress:  0% Loss: 3.547\n",
            "Epoch: 0 Progress:  0% Loss: 3.680\n",
            "Epoch: 0 Progress:  0% Loss: 3.356\n",
            "Epoch: 0 Progress:  0% Loss: 3.379\n",
            "Epoch: 0 Progress:  0% Loss: 3.476\n",
            "Epoch: 0 Progress:  0% Loss: 3.372\n",
            "Epoch: 0 Progress:  0% Loss: 3.288\n",
            "Epoch: 0 Progress:  0% Loss: 3.345\n",
            "Epoch: 0 Progress:  0% Loss: 2.997\n",
            "Epoch: 0 Progress:  0% Loss: 3.141\n",
            "Epoch: 0 Progress:  0% Loss: 3.428\n",
            "Epoch: 0 Progress:  0% Loss: 3.147\n",
            "Epoch: 0 Progress:  0% Loss: 3.085\n",
            "Epoch: 0 Progress:  0% Loss: 2.928\n",
            "Epoch: 0 Progress:  0% Loss: 3.189\n",
            "Epoch: 0 Progress:  0% Loss: 3.200\n",
            "Epoch: 0 Progress:  0% Loss: 3.045\n",
            "Epoch: 0 Progress:  0% Loss: 3.274\n",
            "Epoch: 0 Progress:  0% Loss: 2.933\n",
            "Epoch: 0 Progress:  0% Loss: 3.049\n",
            "Epoch: 0 Progress:  0% Loss: 3.009\n",
            "Epoch: 0 Progress:  0% Loss: 3.014\n",
            "Epoch: 0 Progress:  0% Loss: 2.815\n",
            "Epoch: 0 Progress:  0% Loss: 2.919\n",
            "Epoch: 0 Progress:  0% Loss: 2.829\n",
            "Epoch: 0 Progress:  0% Loss: 2.348\n",
            "Epoch: 0 Progress:  0% Loss: 2.720\n",
            "Epoch: 0 Progress:  0% Loss: 2.996\n",
            "Epoch: 0 Progress:  0% Loss: 2.887\n",
            "Epoch: 0 Progress:  0% Loss: 2.930\n",
            "Epoch: 0 Progress:  0% Loss: 2.880\n",
            "Epoch: 0 Progress:  0% Loss: 2.978\n",
            "Epoch: 0 Progress:  0% Loss: 2.820\n",
            "Epoch: 0 Progress:  0% Loss: 2.199\n",
            "Epoch: 0 Progress:  0% Loss: 2.729\n",
            "Epoch: 0 Progress:  0% Loss: 3.132\n",
            "Epoch: 0 Progress:  0% Loss: 2.913\n",
            "Epoch: 0 Progress:  0% Loss: 3.423\n",
            "Epoch: 0 Progress:  0% Loss: 2.793\n",
            "Epoch: 0 Progress:  0% Loss: 2.954\n",
            "Epoch: 0 Progress:  0% Loss: 2.872\n",
            "Epoch: 0 Progress:  0% Loss: 2.704\n",
            "Epoch: 0 Progress:  0% Loss: 2.819\n",
            "Epoch: 0 Progress:  0% Loss: 3.089\n",
            "Epoch: 0 Progress:  0% Loss: 2.706\n",
            "Epoch: 0 Progress:  0% Loss: 2.713\n",
            "Epoch: 0 Progress:  0% Loss: 2.615\n",
            "Epoch: 0 Progress:  0% Loss: 2.999\n",
            "Epoch: 0 Progress:  0% Loss: 2.450\n",
            "Epoch: 0 Progress:  0% Loss: 2.930\n",
            "Epoch: 0 Progress:  0% Loss: 2.278\n",
            "Epoch: 0 Progress:  0% Loss: 2.594\n",
            "Epoch: 0 Progress:  0% Loss: 2.857\n",
            "Epoch: 0 Progress:  0% Loss: 2.671\n",
            "Epoch: 0 Progress:  0% Loss: 2.595\n",
            "Epoch: 0 Progress:  0% Loss: 2.586\n",
            "Epoch: 0 Progress:  0% Loss: 2.741\n",
            "Epoch: 0 Progress:  0% Loss: 2.540\n",
            "Epoch: 0 Progress:  0% Loss: 2.626\n",
            "Epoch: 0 Progress:  0% Loss: 2.665\n",
            "Epoch: 0 Progress:  0% Loss: 2.610\n",
            "Epoch: 0 Progress:  0% Loss: 2.749\n",
            "Epoch: 0 Progress:  0% Loss: 2.734\n",
            "Epoch: 0 Progress:  0% Loss: 2.473\n",
            "Epoch: 0 Progress:  0% Loss: 2.450\n",
            "Epoch: 0 Progress:  0% Loss: 2.750\n",
            "Epoch: 0 Progress:  0% Loss: 2.729\n",
            "Epoch: 0 Progress:  0% Loss: 2.454\n",
            "Epoch: 0 Progress:  0% Loss: 2.685\n",
            "Epoch: 0 Progress:  0% Loss: 2.435\n",
            "Epoch: 0 Progress:  0% Loss: 2.374\n",
            "Epoch: 0 Progress:  0% Loss: 2.395\n",
            "Epoch: 0 Progress:  0% Loss: 2.504\n",
            "Epoch: 0 Progress:  0% Loss: 1.800\n",
            "Epoch: 0 Progress:  0% Loss: 2.718\n",
            "Epoch: 0 Progress:  0% Loss: 2.488\n",
            "Epoch: 0 Progress:  0% Loss: 2.400\n",
            "Epoch: 0 Progress:  0% Loss: 2.549\n",
            "Epoch: 0 Progress:  0% Loss: 2.452\n",
            "Epoch: 0 Progress:  0% Loss: 2.613\n",
            "Epoch: 0 Progress:  0% Loss: 2.638\n",
            "Epoch: 0 Progress:  0% Loss: 2.466\n",
            "Epoch: 0 Progress:  0% Loss: 2.672\n",
            "Epoch: 0 Progress:  0% Loss: 2.523\n",
            "Epoch: 0 Progress:  0% Loss: 2.817\n",
            "Epoch: 0 Progress:  0% Loss: 2.578\n",
            "Epoch: 0 Progress:  0% Loss: 2.572\n",
            "Epoch: 0 Progress:  0% Loss: 2.364\n",
            "Epoch: 0 Progress:  0% Loss: 2.932\n",
            "Epoch: 0 Progress:  0% Loss: 3.126\n",
            "Epoch: 0 Progress:  0% Loss: 2.884\n",
            "Epoch: 0 Progress:  0% Loss: 2.797\n",
            "Epoch: 0 Progress:  0% Loss: 2.504\n",
            "Epoch: 0 Progress:  0% Loss: 2.701\n",
            "Epoch: 0 Progress:  0% Loss: 2.572\n",
            "Epoch: 0 Progress:  0% Loss: 3.229\n",
            "Epoch: 0 Progress:  0% Loss: 2.570\n",
            "Epoch: 0 Progress:  0% Loss: 2.486\n",
            "Epoch: 0 Progress:  0% Loss: 2.557\n",
            "Epoch: 0 Progress:  0% Loss: 2.641\n",
            "Epoch: 0 Progress:  0% Loss: 2.500\n",
            "Epoch: 0 Progress:  0% Loss: 2.210\n",
            "Epoch: 0 Progress:  0% Loss: 2.504\n",
            "Epoch: 0 Progress:  0% Loss: 2.419\n",
            "Epoch: 0 Progress:  0% Loss: 1.453\n",
            "Epoch: 0 Progress:  0% Loss: 2.862\n",
            "Epoch: 0 Progress:  0% Loss: 2.600\n",
            "Epoch: 0 Progress:  0% Loss: 2.069\n",
            "Epoch: 0 Progress:  0% Loss: 2.280\n",
            "Epoch: 0 Progress:  0% Loss: 2.318\n",
            "Epoch: 0 Progress:  0% Loss: 2.607\n",
            "Epoch: 0 Progress:  0% Loss: 3.467\n",
            "Epoch: 0 Progress:  0% Loss: 2.530\n",
            "Epoch: 0 Progress:  0% Loss: 0.643\n",
            "Epoch: 0 Progress:  0% Loss: 2.723\n",
            "Epoch: 0 Progress:  0% Loss: 2.562\n",
            "Epoch: 0 Progress:  0% Loss: 2.925\n",
            "Epoch: 0 Progress:  0% Loss: 2.488\n",
            "Epoch: 0 Progress:  0% Loss: 2.053\n",
            "Epoch: 0 Progress:  0% Loss: 2.650\n",
            "Epoch: 0 Progress:  0% Loss: 1.786\n",
            "Epoch: 0 Progress:  0% Loss: 2.495\n",
            "Epoch: 0 Progress:  0% Loss: 1.859\n",
            "Epoch: 0 Progress:  0% Loss: 2.464\n",
            "Epoch: 0 Progress:  0% Loss: 2.333\n",
            "Epoch: 0 Progress:  0% Loss: 5.571\n",
            "Epoch: 0 Progress:  0% Loss: 2.516\n",
            "Epoch: 0 Progress:  0% Loss: 2.725\n",
            "Epoch: 0 Progress:  0% Loss: 2.452\n",
            "Epoch: 0 Progress:  0% Loss: 2.421\n",
            "Epoch: 0 Progress:  0% Loss: 2.336\n",
            "Epoch: 0 Progress:  0% Loss: 2.662\n",
            "Epoch: 0 Progress:  0% Loss: 2.341\n",
            "Epoch: 0 Progress:  0% Loss: 2.658\n",
            "Epoch: 0 Progress:  0% Loss: 2.361\n",
            "Epoch: 0 Progress:  0% Loss: 2.475\n",
            "Epoch: 0 Progress:  0% Loss: 2.617\n",
            "Epoch: 0 Progress:  0% Loss: 1.990\n",
            "Epoch: 0 Progress:  0% Loss: 2.418\n",
            "Epoch: 0 Progress:  0% Loss: 2.805\n",
            "Epoch: 0 Progress:  0% Loss: 2.475\n",
            "Epoch: 0 Progress:  0% Loss: 2.407\n",
            "Epoch: 0 Progress:  0% Loss: 2.258\n",
            "Epoch: 0 Progress:  0% Loss: 1.789\n",
            "Epoch: 0 Progress:  0% Loss: 2.379\n",
            "Epoch: 0 Progress:  0% Loss: 1.972\n",
            "Epoch: 0 Progress:  0% Loss: 2.432\n",
            "Epoch: 0 Progress:  0% Loss: 2.353\n",
            "Epoch: 0 Progress:  0% Loss: 2.297\n",
            "Epoch: 0 Progress:  0% Loss: 3.212\n",
            "Epoch: 0 Progress:  0% Loss: 2.835\n",
            "Epoch: 0 Progress:  0% Loss: 2.677\n",
            "Epoch: 0 Progress:  0% Loss: 2.688\n",
            "Epoch: 0 Progress:  0% Loss: 2.399\n",
            "Epoch: 0 Progress:  0% Loss: 2.818\n",
            "Epoch: 0 Progress:  0% Loss: 1.372\n",
            "Epoch: 0 Progress:  0% Loss: 2.386\n",
            "Epoch: 0 Progress:  0% Loss: 1.429\n",
            "Epoch: 0 Progress:  0% Loss: 2.450\n",
            "Epoch: 0 Progress:  0% Loss: 2.473\n",
            "Epoch: 0 Progress:  0% Loss: 2.544\n",
            "Epoch: 0 Progress:  0% Loss: 2.541\n",
            "Epoch: 0 Progress:  0% Loss: 2.547\n",
            "Epoch: 0 Progress:  0% Loss: 2.687\n",
            "Epoch: 0 Progress:  0% Loss: 2.504\n",
            "Epoch: 0 Progress:  0% Loss: 2.400\n",
            "Epoch: 0 Progress:  0% Loss: 3.200\n",
            "Epoch: 0 Progress:  0% Loss: 2.366\n",
            "Epoch: 0 Progress:  0% Loss: 2.406\n",
            "Epoch: 0 Progress:  0% Loss: 2.495\n",
            "Epoch: 0 Progress:  0% Loss: 2.355\n",
            "Epoch: 0 Progress:  0% Loss: 2.359\n",
            "Epoch: 0 Progress:  0% Loss: 2.549\n",
            "Epoch: 0 Progress:  0% Loss: 2.532\n",
            "Epoch: 0 Progress:  0% Loss: 1.452\n",
            "Epoch: 0 Progress:  0% Loss: 2.510\n",
            "Epoch: 0 Progress:  0% Loss: 1.947\n",
            "Epoch: 0 Progress:  0% Loss: 2.400\n",
            "Epoch: 0 Progress:  0% Loss: 2.484\n",
            "Epoch: 0 Progress:  0% Loss: 2.764\n",
            "Epoch: 0 Progress:  0% Loss: 2.340\n",
            "Epoch: 0 Progress:  0% Loss: 2.406\n",
            "Epoch: 0 Progress:  0% Loss: 2.333\n",
            "Epoch: 0 Progress:  0% Loss: 2.260\n",
            "Epoch: 0 Progress:  0% Loss: 2.755\n",
            "Epoch: 0 Progress:  0% Loss: 2.499\n",
            "Epoch: 0 Progress:  0% Loss: 1.963\n",
            "Epoch: 0 Progress:  0% Loss: 2.500\n",
            "Epoch: 0 Progress:  0% Loss: 2.749\n",
            "Epoch: 0 Progress:  0% Loss: 2.573\n",
            "Epoch: 0 Progress:  0% Loss: 2.230\n",
            "Epoch: 0 Progress:  0% Loss: 2.474\n",
            "Epoch: 0 Progress:  0% Loss: 3.183\n",
            "Epoch: 0 Progress:  0% Loss: 1.949\n",
            "Epoch: 0 Progress:  0% Loss: 2.617\n",
            "Epoch: 0 Progress:  0% Loss: 2.499\n",
            "Epoch: 0 Progress:  0% Loss: 2.532\n",
            "Epoch: 0 Progress:  0% Loss: 2.305\n",
            "Epoch: 0 Progress:  0% Loss: 2.807\n",
            "Epoch: 0 Progress:  0% Loss: 2.392\n",
            "Epoch: 0 Progress:  0% Loss: 2.261\n",
            "Epoch: 0 Progress:  0% Loss: 1.565\n",
            "Epoch: 0 Progress:  0% Loss: 2.435\n",
            "Epoch: 0 Progress:  0% Loss: 2.571\n",
            "Epoch: 0 Progress:  0% Loss: 2.418\n",
            "Epoch: 0 Progress:  0% Loss: 2.452\n",
            "Epoch: 0 Progress:  0% Loss: 2.286\n",
            "Epoch: 0 Progress:  0% Loss: 2.294\n",
            "Epoch: 0 Progress:  0% Loss: 2.080\n",
            "Epoch: 0 Progress:  0% Loss: 2.192\n",
            "Epoch: 0 Progress:  0% Loss: 2.391\n",
            "Epoch: 0 Progress:  0% Loss: 2.341\n",
            "Epoch: 0 Progress:  0% Loss: 2.428\n",
            "Epoch: 0 Progress:  0% Loss: 2.467\n",
            "Epoch: 0 Progress:  0% Loss: 2.657\n",
            "Epoch: 0 Progress:  0% Loss: 2.125\n",
            "Epoch: 0 Progress:  0% Loss: 2.295\n",
            "Epoch: 0 Progress:  0% Loss: 2.465\n",
            "Epoch: 0 Progress:  0% Loss: 2.198\n",
            "Epoch: 0 Progress:  0% Loss: 2.298\n",
            "Epoch: 0 Progress:  0% Loss: 2.355\n",
            "Epoch: 0 Progress:  0% Loss: 2.374\n",
            "Epoch: 0 Progress:  0% Loss: 2.344\n",
            "Epoch: 0 Progress:  0% Loss: 2.168\n",
            "Epoch: 0 Progress:  0% Loss: 2.261\n",
            "Epoch: 0 Progress:  0% Loss: 2.265\n",
            "Epoch: 0 Progress:  0% Loss: 2.405\n",
            "Epoch: 0 Progress:  0% Loss: 2.740\n",
            "Epoch: 0 Progress:  0% Loss: 2.353\n",
            "Epoch: 0 Progress:  0% Loss: 2.512\n",
            "Epoch: 0 Progress:  0% Loss: 2.424\n",
            "Epoch: 0 Progress:  0% Loss: 2.441\n",
            "Epoch: 0 Progress:  0% Loss: 2.186\n",
            "Epoch: 0 Progress:  0% Loss: 2.248\n",
            "Epoch: 0 Progress:  0% Loss: 2.237\n",
            "Epoch: 0 Progress:  0% Loss: 2.079\n",
            "Epoch: 0 Progress:  0% Loss: 2.484\n",
            "Epoch: 0 Progress:  0% Loss: 2.330\n",
            "Epoch: 0 Progress:  0% Loss: 2.094\n",
            "Epoch: 0 Progress:  0% Loss: 2.507\n",
            "Epoch: 0 Progress:  0% Loss: 1.993\n",
            "Epoch: 0 Progress:  0% Loss: 2.468\n",
            "Epoch: 0 Progress:  0% Loss: 2.459\n",
            "Epoch: 0 Progress:  0% Loss: 1.890\n",
            "Epoch: 0 Progress:  0% Loss: 1.793\n",
            "Epoch: 0 Progress:  0% Loss: 2.499\n",
            "Epoch: 0 Progress:  0% Loss: 2.284\n",
            "Epoch: 0 Progress:  0% Loss: 2.432\n",
            "Epoch: 0 Progress:  0% Loss: 2.188\n",
            "Epoch: 0 Progress:  0% Loss: 2.805\n",
            "Epoch: 0 Progress:  0% Loss: 2.412\n",
            "Epoch: 0 Progress:  0% Loss: 2.148\n",
            "Epoch: 0 Progress:  0% Loss: 2.460\n",
            "Epoch: 0 Progress:  0% Loss: 1.446\n",
            "Epoch: 0 Progress:  0% Loss: 2.393\n",
            "Epoch: 0 Progress:  0% Loss: 2.433\n",
            "Epoch: 0 Progress:  0% Loss: 2.322\n",
            "Epoch: 0 Progress:  0% Loss: 2.060\n",
            "Epoch: 0 Progress:  0% Loss: 2.472\n",
            "Epoch: 0 Progress:  0% Loss: 2.458\n",
            "Epoch: 0 Progress:  0% Loss: 2.317\n",
            "Epoch: 0 Progress:  0% Loss: 2.259\n",
            "Epoch: 0 Progress:  0% Loss: 2.932\n",
            "Epoch: 0 Progress:  0% Loss: 2.338\n",
            "Epoch: 0 Progress:  0% Loss: 2.289\n",
            "Epoch: 0 Progress:  0% Loss: 2.229\n",
            "Epoch: 0 Progress:  0% Loss: 2.236\n",
            "Epoch: 0 Progress:  0% Loss: 3.032\n",
            "Epoch: 0 Progress:  0% Loss: 2.393\n",
            "Epoch: 0 Progress:  0% Loss: 1.802\n",
            "Epoch: 0 Progress:  0% Loss: 2.362\n",
            "Epoch: 0 Progress:  0% Loss: 2.499\n",
            "Epoch: 0 Progress:  0% Loss: 2.593\n",
            "Epoch: 0 Progress:  0% Loss: 2.186\n",
            "Epoch: 0 Progress:  0% Loss: 2.158\n",
            "Epoch: 0 Progress:  0% Loss: 2.405\n",
            "Epoch: 0 Progress:  0% Loss: 2.396\n",
            "Epoch: 0 Progress:  0% Loss: 2.458\n",
            "Epoch: 0 Progress:  0% Loss: 2.271\n",
            "Epoch: 0 Progress:  0% Loss: 3.247\n",
            "Epoch: 0 Progress:  0% Loss: 2.107\n",
            "Epoch: 0 Progress:  0% Loss: 2.385\n",
            "Epoch: 0 Progress:  0% Loss: 2.354\n",
            "Epoch: 0 Progress:  0% Loss: 2.506\n",
            "Epoch: 0 Progress:  0% Loss: 2.346\n",
            "Epoch: 0 Progress:  0% Loss: 2.061\n",
            "Epoch: 0 Progress:  0% Loss: 2.336\n",
            "Epoch: 0 Progress:  0% Loss: 2.576\n",
            "Epoch: 0 Progress:  0% Loss: 2.324\n",
            "Epoch: 0 Progress:  0% Loss: 1.823\n",
            "Epoch: 0 Progress:  0% Loss: 2.345\n",
            "Epoch: 0 Progress:  0% Loss: 2.430\n",
            "Epoch: 0 Progress:  0% Loss: 1.951\n",
            "Epoch: 0 Progress:  0% Loss: 2.377\n",
            "Epoch: 0 Progress:  0% Loss: 2.321\n",
            "Epoch: 0 Progress:  0% Loss: 2.758\n",
            "Epoch: 0 Progress:  0% Loss: 2.472\n",
            "Epoch: 0 Progress:  0% Loss: 1.384\n",
            "Epoch: 0 Progress:  0% Loss: 2.056\n",
            "Epoch: 0 Progress:  0% Loss: 2.399\n",
            "Epoch: 0 Progress:  0% Loss: 2.444\n",
            "Epoch: 0 Progress:  0% Loss: 2.582\n",
            "Epoch: 0 Progress:  0% Loss: 2.494\n",
            "Epoch: 0 Progress:  0% Loss: 2.161\n",
            "Final F1 score: 0.20\n"
          ]
        }
      ],
      "source": [
        "n_class = len(label_to_idx)\n",
        "\n",
        "# initialize network and optimizer\n",
        "rnn = RNN(n_letters, 256, n_class).cuda()\n",
        "optimizer = torch.optim.SGD(rnn.parameters(), lr=0.01)   \n",
        "\n",
        "# we will train for only a single epoch \n",
        "epochs = 1\n",
        "\n",
        "\n",
        "# main loop\n",
        "for epoch in range(epochs):\n",
        "    \n",
        "    loss_buffer = []\n",
        "    \n",
        "    for i, (x, y) in enumerate(train_loader):  \n",
        "        \n",
        "        x = x.cuda()\n",
        "        y = y.cuda()\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        # get initial hidden state\n",
        "        hidden = rnn.init_hidden(x.shape[0])\n",
        "        \n",
        "        # get output for the sample, remember that we treat it as a sequence\n",
        "        # so you need to iterate over the 2nd, time dimensiotn\n",
        "\n",
        "        seq_len = x.shape[1]\n",
        "        \n",
        "        for i in range(seq_len):\n",
        "          output, hidden = rnn(x[:, i], hidden)\n",
        "            \n",
        "        loss = cross_entropy(output, y)\n",
        "        loss.backward()\n",
        "        optimizer.step()  \n",
        "        \n",
        "        loss_buffer.append(loss.item())\n",
        "        \n",
        "        if i % 1000 == 1:\n",
        "            print(f\"Epoch: {epoch} Progress: {100 * i/len(train_loader):2.0f}% Loss: {np.mean(loss_buffer):.3f}\")\n",
        "            loss_buffer = []\n",
        "    \n",
        "\n",
        "# evaluate on the test set\n",
        "with torch.no_grad():\n",
        "    ps = []\n",
        "    ys = []\n",
        "    correct = 0\n",
        "    for i, (x, y) in enumerate(test_loader):\n",
        "        x = x.cuda()\n",
        "        ys.append(y.numpy())\n",
        "\n",
        "        hidden = rnn.init_hidden(x.shape[0])\n",
        "        seq_len = x.shape[1]\n",
        " \n",
        "        for i in range(seq_len):\n",
        "          output, hidden = rnn(x[:, i], hidden)\n",
        "\n",
        "        pred = output.argmax(dim=1)\n",
        "        ps.append(pred.cpu().numpy())\n",
        "    \n",
        "    ps = np.concatenate(ps, axis=0)\n",
        "    ys = np.concatenate(ys, axis=0)\n",
        "    f1 = f1_score(ys, ps, average='weighted')\n",
        "    \n",
        "    print(f\"Final F1 score: {f1:.2f}\")\n",
        "    assert f1 > 0.15, \"You should get over 0.15 f1 score, try changing some hyperparams!\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sNeNU93qn7BC"
      },
      "source": [
        "## Zadanie 2. (0.5 pkt.)\n",
        "Zaimplementuj funkcje `predict`, która przyjmuje nazwisko w postaci stringa oraz model RNN i wypisuje 3 najlepsze predykcje narodowości dla tego nazwiska razem z ich logitami.\n",
        "\n",
        "**Hint**: Przyda się tutaj jedna z funkcji z pierwszej komórki notebooka."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 274,
      "metadata": {
        "id": "N8FhF_08hAQy"
      },
      "outputs": [],
      "source": [
        "def predict(name: str, rnn: RNN):\n",
        "    \"\"\"Prints the name and model's top 3 predictions with scores\"\"\"\n",
        "    with torch.no_grad():\n",
        "      name = line_to_tensor(name).cuda()\n",
        "      \n",
        "      hidden = rnn.init_hidden(name.shape[0])      \n",
        "      \n",
        "      output, _ = rnn(name, hidden)\n",
        "      \n",
        "      topv, topi = output.topk(3, 1, True)\n",
        "      for i in range(3):\n",
        "        value = topv[0][i].item()\n",
        "        category_index = topi[0][i].item()\n",
        "\n",
        "        print('(%.2f) %s' % (value, label_to_idx[category_index]))\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 275,
      "metadata": {
        "id": "Z4OWP8wqhAQy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "88e95653-e5e7-4d62-f0ee-683fe2820818"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Satoshi\n",
            "(-4.12) vietnamese\n",
            "(-4.23) korean\n",
            "(-4.43) chinese\n",
            "Jackson\n",
            "(-4.17) vietnamese\n",
            "(-4.27) korean\n",
            "(-4.30) chinese\n",
            "Schmidhuber\n",
            "(-4.12) vietnamese\n",
            "(-4.23) korean\n",
            "(-4.43) chinese\n",
            "Hinton\n",
            "(-4.24) vietnamese\n",
            "(-4.28) chinese\n",
            "(-4.30) korean\n",
            "Kowalski\n",
            "(-4.07) vietnamese\n",
            "(-4.18) korean\n",
            "(-4.30) chinese\n"
          ]
        }
      ],
      "source": [
        "some_names = [\"Satoshi\", \"Jackson\", \"Schmidhuber\", \"Hinton\", \"Kowalski\"]\n",
        "\n",
        "for name in some_names:\n",
        "    print(name)\n",
        "    predict(name, rnn)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nNETvP06hAQz"
      },
      "source": [
        "## Zadanie 3 (4 pkt.)\n",
        "Ostatnim zadaniem jest implementacji komórki i sieci LSTM. \n",
        "\n",
        "![lstm](https://colah.github.io/posts/2015-08-Understanding-LSTMs/img/LSTM3-chain.png)\n",
        "\n",
        "* W klasie `LSTMCell` ma znaleźć się główna logika LSTMa, czyli wszystkie wagi do stanów `hidden` i `cell` jak i bramek kontrolujących te stany. \n",
        "* W klasie `LSTM` powinno znaleźć się wywołanie komórki LSTM, HINT: poprzednio było w pętli uczenia, teraz przenisiemy to do klasy modelu.\n",
        "* W pętli uczenia należy uzupełnić brakujące wywołania do uczenia i ewaluacji modelu.\n",
        "\n",
        "Zdecydowanie polecam [materiały Chrisa Olaha](http://colah.github.io/posts/2015-08-Understanding-LSTMs/) do zarówno zrozumienia jak i ściągi do wzorów.\n",
        "\n",
        "Zadaniem jest osiągnięcie wartości `f1_score` lepszej niż na sieci RNN, przy prawidłowej implementacji nie powinno być z tym problemów używając podanych hiperparametrów. Dozwolona jest oczywiście zmiana `random seed`.\n",
        "\n",
        "#### Komórka LSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 276,
      "metadata": {
        "id": "GNKRxYwChAQz"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "class LSTMCell(torch.nn.Module):\n",
        "\n",
        "    def __init__(self, \n",
        "                 input_size: int, \n",
        "                 hidden_size: int):\n",
        "        \"\"\"\n",
        "        :param input_size: int\n",
        "            Dimensionality of the input vector\n",
        "        :param hidden_size: int\n",
        "            Dimensionality of the hidden space\n",
        "        \"\"\"\n",
        "        \n",
        "        super(LSTMCell, self).__init__()\n",
        "        \n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        # initialize LSTM weights \n",
        "        # NOTE: there are different approaches that are all correct \n",
        "        # (e.g. single matrix for all input opperations), you can pick\n",
        "        # whichever you like for this task\n",
        "    \n",
        "        #f_t\n",
        "        self.iw_f = torch.nn.Parameter(torch.Tensor(input_size, hidden_size))\n",
        "        self.hw_f = torch.nn.Parameter(torch.Tensor(hidden_size, hidden_size))\n",
        "        self.b_f = torch.nn.Parameter(torch.Tensor(hidden_size))\n",
        "\n",
        "        #i_t\n",
        "        self.iw_i = torch.nn.Parameter(torch.Tensor(input_size, hidden_size))\n",
        "        self.hw_i = torch.nn.Parameter(torch.Tensor(hidden_size, hidden_size))\n",
        "        self.b_i = torch.nn.Parameter(torch.Tensor(hidden_size))\n",
        "        \n",
        "        #c_t\n",
        "        self.iw_c = torch.nn.Parameter(torch.Tensor(input_size, hidden_size))\n",
        "        self.hw_c = torch.nn.Parameter(torch.Tensor(hidden_size, hidden_size))\n",
        "        self.b_c = torch.nn.Parameter(torch.Tensor(hidden_size))\n",
        "        \n",
        "        #o_t\n",
        "        self.iw_o = torch.nn.Parameter(torch.Tensor(input_size, hidden_size))\n",
        "        self.hw_o = torch.nn.Parameter(torch.Tensor(hidden_size, hidden_size))\n",
        "        self.b_o = torch.nn.Parameter(torch.Tensor(hidden_size))\n",
        "\n",
        "        self.init_weights()\n",
        "\n",
        "    def init_weights(self):\n",
        "            stdv = 1.0 / math.sqrt(self.hidden_size)\n",
        "            for weight in self.parameters():\n",
        "                weight.data.uniform_(-stdv, stdv)\n",
        "\n",
        "    def forward(self, \n",
        "                input: torch.tensor, \n",
        "                states: Tuple[torch.tensor, torch.tensor]) -> Tuple[torch.tensor, torch.tensor]:\n",
        "        \n",
        "        hidden, cell = states\n",
        "        \n",
        "        # Compute input, forget, and output gates\n",
        "        # then compute new cell state and hidden state\n",
        "        # see http://colah.github.io/posts/2015-08-Understanding-LSTMs/ \n",
        "        \n",
        "\n",
        "        f_t = torch.sigmoid(input @ self.iw_f + hidden @ self.hw_f + self.b_f)\n",
        "        i_t = torch.sigmoid(input @ self.iw_i + hidden @ self.hw_i + self.b_i)\n",
        "        c_t = torch.tanh(input @ self.iw_c + hidden @ self.hw_c + self.b_c)\n",
        "        o_t = torch.sigmoid(input @ self.iw_o + hidden @ self.hw_o + self.b_o)\n",
        "\n",
        "        cell = f_t * cell + i_t * c_t\n",
        "        \n",
        "        hidden = o_t * torch.tanh(cell)\n",
        "        \n",
        "        return hidden, cell"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5U5U8kizhAQz"
      },
      "source": [
        "### Klasa modelu LSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 277,
      "metadata": {
        "id": "G2MyIu3_hAQz"
      },
      "outputs": [],
      "source": [
        "class LSTM(torch.nn.Module):\n",
        "\n",
        "    def __init__(self, \n",
        "                 input_size: int, \n",
        "                 hidden_size: int):\n",
        "        \"\"\"\n",
        "        :param input_size: int\n",
        "            Dimensionality of the input vector\n",
        "        :param hidden_size: int\n",
        "            Dimensionality of the hidden space\n",
        "        \"\"\"\n",
        "        \n",
        "        super(LSTM, self).__init__()\n",
        "        \n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.cell = LSTMCell(input_size=input_size, hidden_size=hidden_size)\n",
        "        \n",
        "    def forward(self, \n",
        "                input: torch.tensor) -> Tuple[torch.tensor, torch.tensor]:\n",
        "        \"\"\"\n",
        "        :param input: torch.tensor \n",
        "            Input tesnor for a single observation at timestep t\n",
        "            shape [batch_size, input_size]\n",
        "        Returns Tuple of two torch.tensors, both of shape [seq_len, batch_size, hidden_size]\n",
        "        \"\"\"\n",
        "        \n",
        "        batch_size = input.shape[0]\n",
        "        \n",
        "        hidden, cell = self.init_hidden_cell(batch_size)\n",
        "        \n",
        "        hiddens = []\n",
        "        cells = []\n",
        "        \n",
        "        # this time we will process the whole sequence in the forward method\n",
        "        # as oppose to the previous exercise, remember to loop over the timesteps\n",
        "        \n",
        "        time_steps = input.shape[1]\n",
        "\n",
        "        for i in range(time_steps):\n",
        "          hidden, cell = self.cell(input[:, i], (hidden, cell))\n",
        "          hiddens.append(hidden)\n",
        "          cells.append(cell)\n",
        "\n",
        "\n",
        "        hiddens = hiddens[-1].squeeze()\n",
        "        cells = hiddens[-1].squeeze()\n",
        "        return hiddens, cells\n",
        "    \n",
        "    def init_hidden_cell(self, batch_size):\n",
        "        \"\"\"\n",
        "        Returns initial value for the hidden and cell states\n",
        "        \"\"\"\n",
        "        return (torch.zeros(batch_size, self.hidden_size, requires_grad=True).cuda(), \n",
        "                torch.zeros(batch_size, self.hidden_size, requires_grad=True).cuda())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3qRxPI-nhAQz"
      },
      "source": [
        "### Pętla uczenia"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 278,
      "metadata": {
        "id": "4LVCWqsVhAQ0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "67ec98e5-3f35-4e57-a2b5-c8b3e5479bc2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0 Progress:  0% Loss: 2.853\n",
            "Epoch: 0 Progress:  6% Loss: 2.786\n",
            "Epoch: 0 Progress: 11% Loss: 2.547\n",
            "Epoch: 0 Progress: 17% Loss: 2.395\n",
            "Epoch: 0 Progress: 22% Loss: 2.314\n",
            "Epoch: 0 Progress: 28% Loss: 2.233\n",
            "Epoch: 0 Progress: 33% Loss: 2.223\n",
            "Epoch: 0 Progress: 39% Loss: 2.146\n",
            "Epoch: 0 Progress: 44% Loss: 2.170\n",
            "Epoch: 0 Progress: 50% Loss: 2.064\n",
            "Epoch: 0 Progress: 55% Loss: 2.076\n",
            "Epoch: 0 Progress: 61% Loss: 2.035\n",
            "Epoch: 0 Progress: 66% Loss: 1.985\n",
            "Epoch: 0 Progress: 72% Loss: 2.011\n",
            "Epoch: 0 Progress: 77% Loss: 1.993\n",
            "Epoch: 0 Progress: 83% Loss: 1.988\n",
            "Epoch: 0 Progress: 89% Loss: 1.962\n",
            "Epoch: 0 Progress: 94% Loss: 2.030\n",
            "Epoch: 0 Progress: 100% Loss: 1.971\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:64: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final F1 score: 0.21\n"
          ]
        }
      ],
      "source": [
        "from itertools import chain\n",
        "\n",
        "# torch.manual_seed(1337)\n",
        "\n",
        "# build data loaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=1, sampler=sampler)\n",
        "test_loader = DataLoader(test_dataset, batch_size=1)\n",
        "\n",
        "# initialize the lstm with an additional cliassifier layer at the top\n",
        "lstm = LSTM(input_size=len(all_letters), hidden_size=128).cuda()\n",
        "clf = torch.nn.Linear(in_features=128, out_features=len(label_to_idx)).cuda()\n",
        "\n",
        "# initialize a optimizer\n",
        "params = chain(lstm.parameters(), clf.parameters())\n",
        "optimizer = torch.optim.Adam(params, lr=0.01) \n",
        "\n",
        "# we will train for only a single epoch \n",
        "epoch = 1\n",
        "\n",
        "# main loop\n",
        "for epoch in range(epoch):\n",
        "    \n",
        "    loss_buffer = []\n",
        "    \n",
        "    for i, (x, y) in enumerate(train_loader):   \n",
        "        \n",
        "        x = x.cuda()\n",
        "        y = y.cuda()\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        # get output for the sample, remember that we treat it as a sequence\n",
        "        # so you need to iterate over the sequence length here\n",
        "        # don't forget about the classifier!\n",
        "\n",
        "        output, _ = lstm(x)\n",
        "        output = torch.tensor(output)\n",
        "\n",
        "        output = clf(output).reshape(1, len(label_to_idx))\n",
        "        \n",
        "        # calucate the loss\n",
        "\n",
        "        loss = cross_entropy(output, y)\n",
        "        loss.backward()\n",
        "        optimizer.step()                                \n",
        "        \n",
        "        loss_buffer.append(loss.item())\n",
        "        \n",
        "        if i % 1000 == 1:\n",
        "            print(f\"Epoch: {epoch} Progress: {100 * i/len(train_loader):2.0f}% Loss: {np.mean(loss_buffer):.3f}\")\n",
        "            loss_buffer = []\n",
        "\n",
        "# evaluate on the test set\n",
        "with torch.no_grad():\n",
        "    \n",
        "    ps = []\n",
        "    ys = []\n",
        "    for i, (x, y) in enumerate(test_loader): \n",
        "        \n",
        "        x = x.cuda()\n",
        "        ys.append(y.numpy())\n",
        "        \n",
        "        output, _ = lstm(x)\n",
        "        output = torch.tensor(output)\n",
        "\n",
        "        output = clf(output).reshape(1, 18)\n",
        "\n",
        "        pred = output.argmax(dim=1)\n",
        "        ps.append(pred.cpu().numpy())\n",
        "    \n",
        "    ps = np.concatenate(ps, axis=0)\n",
        "    ys = np.concatenate(ys, axis=0)\n",
        "    f1 = f1_score(ys, ps, average='weighted')\n",
        "    \n",
        "    print(f\"Final F1 score: {f1:.2f}\")\n",
        "    assert f1 > 0.18, \"You should get over 0.18 f1 score, try changing some hiperparams!\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gGXUhgroo7AN"
      },
      "source": [
        "## Zadanie 4. (0.5 pkt.)\n",
        "Zaimplementuj analogiczną do funkcji `predict` z zadania 2 dla modelu `lstm+clf`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 279,
      "metadata": {
        "id": "-ChJv1fphAQ0"
      },
      "outputs": [],
      "source": [
        "def predict_lstm(name: str, lstm: LSTM, clf: torch.nn.Module):\n",
        "    \"\"\"Prints the name and model's top 3 predictions with scores\"\"\"\n",
        "    with torch.no_grad():\n",
        "      name = line_to_tensor(name).cuda()\n",
        "\n",
        "      output, _ = lstm(name)\n",
        "\n",
        "      output = clf(output).reshape(1, len(label_to_idx))\n",
        "      \n",
        "      topv, topi = output.topk(3, 1, True)\n",
        "\n",
        "      for i in range(3):\n",
        "        value = topv[0][i].item()\n",
        "        category_index = topi[0][i].item()\n",
        "\n",
        "        print('(%.2f) %s' % (value, label_to_idx[category_index]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 280,
      "metadata": {
        "id": "pgQcGWqthAQ0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "outputId": "8807fcd8-e4c4-4de3-faf8-c7ce697ddc5c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Satoshi\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-280-e816651c6657>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msome_names\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mpredict_lstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlstm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-279-7687eb719761>\u001b[0m in \u001b[0;36mpredict_lstm\u001b[0;34m(name, lstm, clf)\u001b[0m\n\u001b[1;32m      4\u001b[0m       \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mline_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m       \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m       \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel_to_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-277-e629e2a078cf>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m           \u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m           \u001b[0mhiddens\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m           \u001b[0mcells\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-276-da4ad254b161>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, states)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m         \u001b[0mf_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miw_f\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhw_f\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mb_f\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m         \u001b[0mi_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miw_i\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhw_i\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mb_i\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0mc_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtanh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miw_c\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhw_c\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mb_c\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (1x7 and 52x128)"
          ]
        }
      ],
      "source": [
        "# test your lstm predictor\n",
        "some_names = [\"Satoshi\", \"Jackson\", \"Schmidhuber\", \"Hinton\", \"Kowalski\"]\n",
        "    \n",
        "for name in some_names:\n",
        "    print(name)\n",
        "    predict_lstm(name, lstm, clf)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "laVdd5g5hAQu"
      ],
      "name": "11_RNN.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}